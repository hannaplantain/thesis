{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook (...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PARAMETERS\n",
    "N = 4 # length of each genome\n",
    "K_i = 2 # ruggedness parameter of the NK model for individual fitness\n",
    "K_g = K_i # ruggedness parameter of the NK model for groups\n",
    "M = 3 # number of groups\n",
    "n =  5 # maximum number of individuals per group\n",
    "mu = 0.1 # when mutation takes place: mutation rate per gene - find good value\n",
    "\n",
    "I = n*M # total number of individuals (max as starting out with full groups). If changed to less, I must > M as groups cannot be empty\n",
    "alpha = 1/10 # generation time of groups relative to that of individuals \n",
    "t_end = 10 # duration of simulation\n",
    "\n",
    "# NEUTRALIY\n",
    "\"\"\"\n",
    "choose \"NK\" for regular NK, \n",
    "\"NKp\" for probabilistic NK, \n",
    "\"NKq\" for quantised NK\n",
    "\"\"\"\n",
    "neutrality_i = [\"NK\"] \n",
    "neutrality_g = [\"NK\"] \n",
    "p_i = 0.5 # p of NKp for individual-level fitness\n",
    "p_g = p_i # p of NKp for group-level fitness\n",
    "q_i = 4 # q of NKq for individual-level fitness\n",
    "q_g = q_i # q of NKq for group-level fitness\n",
    "\n",
    "# NETWORK PROPERTIES\n",
    "\"\"\"\n",
    "choose \"r\" for sampling with replacement, \n",
    "\"nr\" for without replacement, \n",
    "\"block\" for blockwise interactions\n",
    "\"\"\"\n",
    "network_i = [\"r\"]\n",
    "network_g = [\"r\"]\n",
    "\n",
    "# MUTATION PROBABILITY\n",
    "\"\"\"\n",
    "choose \"yes\" for  reproduction with mutation, \n",
    "\"no\" for reproduction without mutation, \n",
    "\"\"\"\n",
    "mutation = [\"yes\"]\n",
    "\n",
    "# SIMULATION PARAMETERS\n",
    "my_seed = 10 # random seed\n",
    "t_end = 10 # end time, in units of individual generation times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import math\n",
    "from numpy.random import choice \n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from builtins import ValueError\n",
    "#set style for all plots\n",
    "plot.style.use(\"seaborn-v0_8-colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shorthands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_i = 2**(K_i + 1) # number of hypercube corners for the fitness contributions of each gene\n",
    "# (= columns in fitness matrix) at the individual level \n",
    "B_g = 2**(K_g + 1) # number of hypercube corners for the fitness contributions of each gene\n",
    "# (= columns in fitness matrix) at the group level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitness matrix\n",
    "fm_i = np.zeros((N, B_i)) # invullen: lege array N x B_j\n",
    "fm_g = np.zeros((N, B_g)) # invullen: lege arry N x B_g\n",
    "# epistasis matrices\n",
    "val = list(range(0, N))\n",
    "\n",
    "# fitness values\n",
    "#f_i = # absolute fitness individual level\n",
    "f_i_comp = np.random.rand(I, N) #randomly generates fitness contributions associated with gene values of all individuals\n",
    "f_i = np.mean(f_i_comp, axis=1,) #absolute fitness of all individuals (=avg by row of f_i_comp)\n",
    "f_i = f_i.reshape(-1, 1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for constructing fitness landscapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fitness_matrix_i():\n",
    "    fm_i = np.random.rand(N, B_i)\n",
    "    match neutrality_i:\n",
    "        case [\"NK\"]:\n",
    "            #\n",
    "            pass\n",
    "        case [\"NKp\"]:\n",
    "            fm_i = np.where(np.random.rand(*fm_i.shape) < p_i, 0, fm_i) \n",
    "        case [\"NKq\"]:\n",
    "            fm_i = np.digitize(fm_i, bins=np.linspace(0, 1, q_i+1), right=True) - 1\n",
    "    return fm_i\n",
    "\n",
    "def create_fitness_matrix_g():\n",
    "    fm_g = np.random.rand(N, B_g)\n",
    "    match neutrality_g:\n",
    "        case [\"NK\"]:\n",
    "            #\n",
    "            pass\n",
    "        case [\"NKp\"]:\n",
    "            fm_g = np.where(np.random.rand(*fm_g.shape) < p_g, 0, fm_g) \n",
    "        case [\"NKq\"]:\n",
    "            fm_g = np.digitize(fm_g, bins=np.linspace(0, 1, q_g+1), right=True) - 1\n",
    "    return fm_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for constructing epistasis matrix without repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_perm_tree(level, nums): \n",
    "    \"\"\"\n",
    "    makes tree structure with all possible permutations of given 'nums',\n",
    "    where each number is allowed to move to next position in permutation, excluding repeats\n",
    "    - level: Current level in the permutation.\n",
    "    - nums (list): list of numbers to permute.\n",
    "    returns:\n",
    "    - dict: nested dictionary representing the permutation tree structure.\n",
    "        Each key is a number, and corresponding value is the subtree for the next level.\n",
    "    \"\"\"\n",
    "    if len(nums) == 1:\n",
    "        if level == nums[0]:\n",
    "            return None\n",
    "        else:\n",
    "            return {nums[0]: {}}\n",
    "    allowed_number = list(nums)\n",
    "    if level in allowed_number:\n",
    "        allowed_number.remove(level)\n",
    "    result = {}\n",
    "    for number in allowed_number:\n",
    "        sublevel_number = list(nums)\n",
    "        if number in sublevel_number:\n",
    "            sublevel_number.remove(number)\n",
    "        subtree = generate_all_perm_tree(level + 1, sublevel_number)\n",
    "        if subtree is not None:\n",
    "            result[number] = subtree\n",
    "    if len(result) == 0:\n",
    "        return None\n",
    "    return result\n",
    "\n",
    "def pick_all_moved_perm(all_moved_perm_tree, picked=None):#picks permutation of numbers from previously generated tree, with each number selected only once\n",
    "    \"\"\"\n",
    "    Picks permutation of numbers from previously generated tree, with each number selected only once\n",
    "    - all_moved_perm_tree (dictionary): The permutation tree generated by generate_all_perm_tree\n",
    "    - picked: set of numbers already picked.\n",
    "    Return:\n",
    "    - list: representing a permutation of numbers\n",
    "    \"\"\"\n",
    "    if picked is None:\n",
    "        picked = set()\n",
    "    allowed_num_set = set(all_moved_perm_tree.keys()) - picked\n",
    "    if not allowed_num_set:\n",
    "        return []\n",
    "    number = rd.choice(list(allowed_num_set))\n",
    "    picked.add(number)\n",
    "    l = [number]\n",
    "    sub_tree = all_moved_perm_tree[number]\n",
    "    if len(sub_tree) > 0:\n",
    "        l.extend(pick_all_moved_perm(sub_tree, picked))\n",
    "    return l\n",
    "\n",
    "def generate_unique_r(tree, num_rows): \n",
    "    \"\"\"\n",
    "    Generates an array of unique pairs of numbers, with no number repeated in a row\n",
    "    - tree (dict):the permutation tree generated by generate_all_moved_perm_tree.\n",
    "    - num_rows: the number of rows to generate.\n",
    "    Returns:\n",
    "    - 2d array representing unique pairs of numbers in each row\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for _ in range(num_rows):\n",
    "        row = list(zip(pick_all_moved_perm(tree), pick_all_moved_perm(tree)))\n",
    "        while any(x[0] == x[1] for x in row):\n",
    "            row = list(zip(pick_all_moved_perm(tree), pick_all_moved_perm(tree)))\n",
    "        result.extend(row)\n",
    "    return np.array(result[:num_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for choosing preferred epistasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epistasis_matrix_i(): #epistasis matrix individual level\n",
    "    em_i = []\n",
    "    match network_i:\n",
    "        case [\"r\"]:\n",
    "            for row in range(N):\n",
    "                val = list(range(0, N))\n",
    "                gene_pair = rd.sample(val[:row] + val[row + 1:], K_i)  \n",
    "                em_i.append([row] + gene_pair)\n",
    "            em_i = np.array(em_i)  #first with own gene referenced\n",
    "            em_i = em_i[:, 1:] #without own gene referenced #remove this row or above\n",
    "        case [\"nr\"]:\n",
    "            tree = generate_all_perm_tree(1, range(1, N+1))\n",
    "            em_i = generate_unique_r(tree, N)\n",
    "        #case [\"block\"]:\n",
    "           # em = #working on it :)\n",
    "    return em_i\n",
    "\n",
    "def create_epistasis_matrix_g():\n",
    "    em_g = []\n",
    "    match network_g:\n",
    "        case [\"r\"]:\n",
    "            val = list(range(N))\n",
    "            for row in range(N):\n",
    "                gene_pair = rd.sample(val[:row] + val[row + 1:], K_g)  # Select K_g unique genes \n",
    "                em_g.append([row] + gene_pair)  # Row number added to the beginning\n",
    "            em_g = np.array(em_g)  # First with own gene referenced\n",
    "            em_g = em_g[:, 1:]\n",
    "        case [\"nr\"]:\n",
    "            tree = generate_all_perm_tree(1, range(1, N+1))\n",
    "            em_g = generate_unique_r(tree, N)\n",
    "        # case [\"block\"]:\n",
    "        #    em = # working on it :)\n",
    "    return em_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for constructing fitness landscapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fitness_matrix_i():\n",
    "    fm_i = np.random.rand(N, B_i)\n",
    "    match neutrality_i:\n",
    "        case [\"NK\"]:\n",
    "            #\n",
    "            pass\n",
    "        case [\"NKp\"]:\n",
    "            fm_i = np.where(np.random.rand(*fm_i.shape) < p_i, 0, fm_i) \n",
    "        case [\"NKq\"]:\n",
    "            fm_i = np.digitize(fm_i, bins=np.linspace(0, 1, q_i+1), right=True) - 1\n",
    "    return fm_i\n",
    "\n",
    "def create_fitness_matrix_g():\n",
    "    fm_g = np.random.rand(N, B_g)\n",
    "    match neutrality_g:\n",
    "        case [\"NK\"]:\n",
    "            #\n",
    "            pass\n",
    "        case [\"NKp\"]:\n",
    "            fm_g = np.where(np.random.rand(*fm_g.shape) < p_g, 0, fm_g) \n",
    "        case [\"NKq\"]:\n",
    "            fm_g = np.digitize(fm_g, bins=np.linspace(0, 1, q_g+1), right=True) - 1\n",
    "    return fm_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for calculating coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_a(fitness_matrix): #other functions split by ind/group but not this one. Do or not? think\n",
    "    \"\"\"\n",
    "    calculate and return coefficients based on fitness matrix \n",
    "    - B: B_g or B_i: number of binary gene combinations = corners hypercube\n",
    "    - fm (array): fm_g or fm_i - fitness matrix individuals or groups\n",
    "    Returns:\n",
    "    - List containing 'a' coefficients for each row of the input matrix\n",
    "    \"\"\"\n",
    "    a_coefficients = []\n",
    "    for r in fitness_matrix:\n",
    "        a = [0.0] * B_g  # initialises list with zeros as floats for each row & X cols\n",
    "        a[0] = r[0] #set ai0 to Fi0 \n",
    "        for j in range(1, B_g): \n",
    "            sum = 0.0 \n",
    "            # Calculate next coefs based only on previously calculated coefs\n",
    "            for l in range(0, j): \n",
    "                #check if l equal to bitwise AND of l and j \n",
    "                #(ex: 001&101->001 TRUE; 001&100->000 FALSE)\n",
    "                if l == (l & j): \n",
    "                    sum += a[l] \n",
    "            a[j] = r[j] - sum \n",
    "        a_coefficients.append(a) # append new a's into result array\n",
    "    return a_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for calculating fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_fitness(coefficients, epistasis, genome, gene):\n",
    "    \"\"\"\n",
    "    Calculate the fitness component of a specific gene in a genome\n",
    "    - coefficients (array): coefficient matrix as calculated by calc_a\n",
    "    - epistasis (\"): Epistasis matrix representing interactions between genes\n",
    "    - genome (\"): genome values\n",
    "    - gene (int): index of specific gene for which fitness component is calculated\n",
    "    Returns:\n",
    "    - fitness component of the specified gene in the genome (float)\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    for j in range(coefficients.shape[1]):\n",
    "        contribution = coefficients[gene, j] * (genome[gene] ** (1 & j))\n",
    "        for k in range(epistasis.shape[1]):\n",
    "            epi_index = (epistasis[gene, k])\n",
    "            epi_value = genome[int(epi_index)]\n",
    "            product_term = epi_value ** ((2**(k+1) & j) / 2**(k+1))\n",
    "            contribution *= product_term\n",
    "\n",
    "        result += contribution\n",
    "    return result\n",
    "\n",
    "def genome_fitness(coefficients, epistasis, genome):\n",
    "    \"\"\"\n",
    "    Calculate fitness components for all genes within a genome \n",
    "    return:\n",
    "    array containing fitness components for each gene in the genome\n",
    "    \"\"\"\n",
    "    fit_vals = np.zeros(len(genome))\n",
    "    for gene in range(len(genome)):\n",
    "        fit_vals[gene] = gene_fitness(coefficients, epistasis, genome, gene)\n",
    "    return fit_vals\n",
    "\n",
    "def calculate_fitness(coefficients, epistasis, genomes):\n",
    "    \"\"\"\n",
    "    Calculate the fitness components for all genes in all genomes\n",
    "    Return:\n",
    "    3D array containing fitness components for each gene (cols) in each genome (rows)\n",
    "    \"\"\"\n",
    "    if len(genomes.shape) == 2:  #add 3rd dimension for compatibitlyt if 2D array(one group)\n",
    "        genomes = np.expand_dims(genomes, axis=0)\n",
    "    fit_val = np.zeros(genomes.shape)\n",
    "    for group in range(genomes.shape[0]):\n",
    "        for individual in range(genomes.shape[1]):\n",
    "            fit_val[group, individual, :] = genome_fitness(coefficients, epistasis, genomes[group, individual, :])\n",
    "    avg_fit = np.mean(fit_val, axis=2)\n",
    "    return avg_fit\n",
    "\n",
    "# CONSTRUCT FITNESS LANDSCAPES \n",
    "fm_i = create_fitness_matrix_i()\n",
    "fm_g = create_fitness_matrix_g()\n",
    "# Construct epistasis matrices\n",
    "em_i = create_epistasis_matrix_i()\n",
    "em_g = create_epistasis_matrix_g()\n",
    "\n",
    "#coefficients\n",
    "coef_i = np.array(calc_a(fm_i))\n",
    "coef_g = np.array(calc_a(fm_g))\n",
    "\n",
    "#print(coef_g)\n",
    "fm_i_avg = np.mean(fm_i, axis=0)\n",
    "#print(fm_i)\n",
    "#print(fm_i_avg)\n",
    "population = np.zeros(shape=(M,n,N))\n",
    "\n",
    "# Add print statements to check array shapes and indices\n",
    "#print(\"Coefficient shape:\", coef_i.shape)\n",
    "#print(\"Epistasis shape:\", em_i.shape)\n",
    "#print(\"Population shape:\", population.shape)\n",
    "#print(population)\n",
    "genomes_example = np.random.randint(0, 2, size = (M, n, N))\n",
    "avg_genomes_example = np.mean(genomes_example, axis = 1)\n",
    "#print(avg_genomes_example)\n",
    "#avg_ind_fit = calculate_binary_fitness(genomes_example, fm_i)\n",
    "#print(\"individual fitnesses:\", avg_ind_fit)\n",
    "fitness = calculate_fitness(coef_g, em_g, avg_genomes_example)\n",
    "#print(fitness)\n",
    "# Call calculate_fitness function\n",
    "#abs_ind_fitness = calculate_fitness(coef_i, em_i, population)\n",
    "#print(abs_ind_fitness)\n",
    "\n",
    "#fitness = np.random.rand(3, 10, 4)\n",
    "#print(fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for updating fitnesses & rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating fitnesses\n",
    "#individual\n",
    "def update_ind_fitness_indrep(event_drawn, population_slice, abs_ind_fitness, coef_i, em_i, offspring_ind_genome, rd_row_index):\n",
    "    \"\"\"\n",
    "    Updates the rates of individual reproduction events after individual reproduction\n",
    "    -abs_ind_fitness: array containing all current individual absolute fitnesses \n",
    "    -coefficients: array with coefficients used for continuous NK based fitness calculation\n",
    "    -epistasis: array with epistatic interactions used for continuous NK based fitness calculation\n",
    "    -offspring_ind_genome: genome of only the new individual\n",
    "    -group_index: index of group slected individual is in\n",
    "    -ind_index: index of selected individual within group\n",
    "    -rd_row_index: index of eliminated individual\n",
    "    Returns: \n",
    "    -abs_ind_fitness = array containing the updated absolute fitnesses (changed and unchanged)\n",
    "    -changed_abs_ind_fitness = array with fitnesses in group in which reproduction happened\n",
    "    \"\"\"\n",
    "    ind_index = (event_drawn- M) % n #within group \n",
    "    group_index = ((event_drawn-M)//n) \n",
    "    parent_ind_genome = population_slice[ind_index]\n",
    "    parent_ind_genome = np.array(parent_ind_genome)    \n",
    "    abs_ind_fitness = np.reshape(abs_ind_fitness, (M, n))   \n",
    "    population_slice_fit = abs_ind_fitness[group_index, :] \n",
    "\n",
    "    if (offspring_ind_genome == parent_ind_genome).all:\n",
    "        offspring_fitness = population_slice_fit[ind_index] #because offspring fitness = fitness selected individual\n",
    "        population_slice_fit[rd_row_index] = offspring_fitness\n",
    "    elif offspring_ind_genome is not parent_ind_genome: #because mutated\n",
    "        offspring_fitness = genome_fitness(coef_i, em_i, offspring_ind_genome) #mutated so need to recalculate\n",
    "        population_slice_fit[rd_row_index] = offspring_fitness\n",
    "        \n",
    "    unchanged_ind_fit = np.delete(abs_ind_fitness, group_index, axis=0) #fitness of inds in all other groups stays the same\n",
    "    changed_abs_ind_fitness = np.reshape(population_slice_fit, (1, n))\n",
    "    abs_ind_fitness = np.append(unchanged_ind_fit, changed_abs_ind_fitness, axis=0)\n",
    "    #np.concatenate((unchanged_ind_fit, population_slice_fit), axis=0) #fix so correctly insert new fitness (in right spot slices?)\n",
    "    \n",
    "    return abs_ind_fitness\n",
    "\n",
    "def update_ind_fitness_grsplit(assign_mask, abs_ind_fitness, group_index, terminated_group_index):\n",
    "    \"\"\"\n",
    "    Updates the rates of individual reproduction events after a group splitting event \n",
    "    -assign_mask: mask created in group splitting function to distribute fitnesses same way as genomes\n",
    "    -abs_ind_fitness: array containing all current individual absolute fitnesses \n",
    "    -group_index: index of group selected for splitting\n",
    "    Returns:\n",
    "    -abs_ind_fitness: array containing all current individual absolute fitnesses (changed and unchanged)\n",
    "    -changed_abs_ind_fitness: array with fitnesses in group in which reproduction happened\n",
    "    \"\"\"\n",
    "\n",
    "    abs_ind_fitness = abs_ind_fitness.reshape((M,n)) #dubbelcheck later\n",
    "    old_parent_group_fitness = abs_ind_fitness[group_index, :] \n",
    "\n",
    "    #parent_group_fitness = old_parent_group_fitness[assign_mask == 0] \n",
    "    parent_group_fitness = np.where(assign_mask == 1, np.nan, old_parent_group_fitness)  \n",
    "    offspring_group_fitness = np.where(assign_mask == 0, np.nan, old_parent_group_fitness) \n",
    "    abs_ind_fitness = np.delete(abs_ind_fitness, group_index, axis=0)  #old parent group veriwjderen\n",
    "\n",
    "    parent_group_fitness_reshape = parent_group_fitness[np.newaxis, :]  #(1, 5)\n",
    "    offspring_group_fitness_reshape = offspring_group_fitness[np.newaxis, :] \n",
    "\n",
    "    abs_ind_fitness = np.concatenate((abs_ind_fitness, parent_group_fitness_reshape, offspring_group_fitness_reshape), axis=0)\n",
    "\n",
    "    #hier terminated_group_index gebruiken om eliminated group te verwijderen\n",
    "    abs_ind_fitness = np.delete(abs_ind_fitness, terminated_group_index, axis=0)\n",
    "    changed_abs_ind_fitness = np.concatenate((parent_group_fitness, offspring_group_fitness), axis=0) #del?\n",
    "    return abs_ind_fitness\n",
    "\n",
    "#group \n",
    "def update_gr_fitness_indrep(abs_gr_fitness, population_slice, event_drawn, coef_g, em_g):\n",
    "    \"\"\"\n",
    "    -population_slice: 2D array with updated genomes of group reproduction happened in\n",
    "    -group index: index of group slected individual is in\n",
    "    -coefficients: array with coefficients used for continuous NK based fitness calculation\n",
    "    -epistasis: array with epistatic interactions used for continuous NK based fitness calculation\n",
    "    Returns:\n",
    "    abs_gr_fitness: 2d array with absolute group fitnesses of all groups \n",
    "    \"\"\"\n",
    "    group_index = ((event_drawn-M)//n) #note both ind_index and group_index start at 0\n",
    "    changed_group_genome = np.nanmean(population_slice, axis=0) #new group genome = avg of change group slice\n",
    "   # print(\"changed group genome\", changed_group_genome)\n",
    "    changed_abs_gr_fitvals = genome_fitness(coef_g, em_g, changed_group_genome) #calculate abs fitness new group genome\n",
    "    changed_abs_gr_fitness = np.mean(changed_abs_gr_fitvals, axis=0)\n",
    "    abs_gr_fitness = abs_gr_fitness.reshape(-1, 1)\n",
    "    abs_gr_fitness[group_index] = changed_abs_gr_fitness\n",
    "    #unchanged_abs_gr_fitness = np.delete(abs_gr_fitness, group_index, axis=0)    \n",
    "    #print(\"unchanged_abs_gr_fitness\", unchanged_abs_gr_fitness)\n",
    "   # print(\"unchanged_abs_gr_fitness shape\", unchanged_abs_gr_fitness.shape)\n",
    "\n",
    "   # abs_gr_fitness = np.concatenate((changed_abs_gr_fitness, unchanged_abs_gr_fitness), axis = 0) #recombine new with old\n",
    "\n",
    "    return abs_gr_fitness\n",
    "\n",
    "def update_gr_fitness_grsplit(abs_gr_fitness, changed_group, changed_group_index, coef_g, em_g): \n",
    "    \"\"\"\n",
    "    -changed_group: 2d/3d array containing changed groups\n",
    "    -changed_group_index: index of changed group or groups, depending on if parent/offspring group gets eliminated or not\n",
    "    -coefficients: array with coefficients used for continuous NK based fitness calculation\n",
    "    -epistasis: array with epistatic interactions used for continuous NK based fitness calculation\n",
    "    Returns: \n",
    "    -abs_gr_fitness: 3d array with absolute group fitnesses of all groups \n",
    "    -changed_abs_gr_fitness: 2d/3d array with absolute group fitness of the changed groups\n",
    "    \"\"\"\n",
    "    if changed_group.ndim > 2:\n",
    "        new_group_genomes = np.nanmean(changed_group, axis=1)\n",
    "        changed_abs_gr_fitness_vals = calculate_fitness(coef_g, em_g, new_group_genomes)\n",
    "        changed_abs_gr_fitness = np.mean(changed_abs_gr_fitness_vals, axis=0)       \n",
    "        changed_abs_gr_fitness = changed_abs_gr_fitness[np.newaxis, :] \n",
    "        changed_abs_gr_fitness = changed_abs_gr_fitness.reshape(-1,1)      \n",
    "    else:\n",
    "        new_group_genomes = np.nanmean(changed_group, axis=0)\n",
    "        changed_abs_gr_fitness_vals = genome_fitness(coef_g, em_g, new_group_genomes)\n",
    "        changed_abs_gr_fitness = np.mean(changed_abs_gr_fitness_vals, axis=0)\n",
    "        changed_abs_gr_fitness = np.array([changed_abs_gr_fitness])     \n",
    "        changed_abs_gr_fitness = changed_abs_gr_fitness[np.newaxis, :]  \n",
    "        changed_abs_gr_fitness = changed_abs_gr_fitness.reshape(-1,1)     \n",
    "\n",
    "    if isinstance(changed_group_index, tuple):\n",
    "        #Unpack tuple\n",
    "        index_1, index_2 = changed_group_index\n",
    "        # Delete both indices from abs_gr_fitness\n",
    "        unchanged_abs_gr_fitness = np.delete(abs_gr_fitness, (index_1, index_2), axis=0)\n",
    "        abs_gr_fitness = np.concatenate((changed_abs_gr_fitness, unchanged_abs_gr_fitness), axis= 0)     \n",
    "    else:\n",
    "        # Delete the single index from abs_gr_fitness\n",
    "        unchanged_abs_gr_fitness = np.delete(abs_gr_fitness, changed_group_index-1, axis=0)\n",
    "        abs_gr_fitness = np.concatenate((changed_abs_gr_fitness, unchanged_abs_gr_fitness), axis= 0)     \n",
    "    #unchanged_abs_gr_fitness = np.delete(abs_gr_fitness, changed_group_index-1, axis=0) #check if index for changed groups works same next line\n",
    "    #abs_gr_fitness = np.concatenate((changed_abs_gr_fitness, unchanged_abs_gr_fitness), axis= 0) \n",
    "    return abs_gr_fitness \n",
    "\n",
    "#Updating rates\n",
    "def update_rates_indrep(event_drawn, population_slice, abs_ind_fitness, abs_gr_fitness, coef_i, em_i, offspring_ind_genome, rd_row_index, coef_g, em_g):\n",
    "    abs_ind_fitness = update_ind_fitness_indrep(event_drawn, population_slice, abs_ind_fitness, coef_i, em_i, offspring_ind_genome, rd_row_index)\n",
    "    abs_ind_fitness = abs_ind_fitness.reshape((M, n))\n",
    "    changed_f_j = np.nanmean(abs_ind_fitness, axis=1) #average group fitness  = average of ind fitnesses check if taking changed or all\n",
    "    w_j = abs_ind_fitness / changed_f_j[:, np.newaxis]    \n",
    "    ind_rates = []\n",
    "    ind_rates = w_j.flatten()\n",
    "    ind_rates = w_j.reshape(-1, 1)    \n",
    "    abs_gr_fitness = update_gr_fitness_indrep(abs_gr_fitness, population_slice, event_drawn, coef_g, em_g)\n",
    "    F = np.mean(abs_gr_fitness)\n",
    "    W = abs_gr_fitness / F\n",
    "    gr_rates = alpha * W\n",
    "    rates = np.vstack((gr_rates, ind_rates))\n",
    "    rates = np.nan_to_num(rates, nan=0)\n",
    "    return rates, abs_ind_fitness, abs_gr_fitness\n",
    "\n",
    "def update_rates_grsplit(abs_ind_fitness, abs_gr_fitness, event_drawn, changed_group, changed_group_index, assign_mask, terminated_group_index, coef_g, em_g): \n",
    "    #group_index = ((event_drawn-M)//n) #note both ind_index and group_index start at 0\n",
    "    group_index = event_drawn // (N // M)\n",
    "    abs_ind_fitness = update_ind_fitness_grsplit(assign_mask, abs_ind_fitness, group_index, terminated_group_index)\n",
    "    changed_f_j = np.nanmean(abs_ind_fitness, axis=1)\n",
    "    changed_f_j = changed_f_j[:, np.newaxis]\n",
    "    w_j = abs_ind_fitness / changed_f_j #check \n",
    "    ind_rates = []\n",
    "    ind_rates = w_j.flatten()\n",
    "    #ind_rates = ind_rates[~np.isnan(ind_rates)]\n",
    "    ind_rates = ind_rates.reshape(-1, 1)         \n",
    "\n",
    "    abs_gr_fitness = update_gr_fitness_grsplit(abs_gr_fitness, changed_group, changed_group_index, coef_g, em_g)\n",
    "    #give groups with one genome fitness 0 (they cannot split)\n",
    "    nan_counts_per_row = np.sum(np.isnan(abs_ind_fitness), axis=1)\n",
    "    rows_to_zero = np.where(nan_counts_per_row == abs_ind_fitness.shape[1] - 1)[0]\n",
    "    abs_gr_fitness[rows_to_zero] = 0\n",
    "\n",
    "    F = np.mean(abs_gr_fitness)\n",
    "    W = abs_gr_fitness / F\n",
    "    gr_rates = alpha * W\n",
    "    gr_rates = gr_rates.reshape(-1, 1)\n",
    "    rates = np.vstack((gr_rates, ind_rates))\n",
    "    rates = np.nan_to_num(rates, nan=0)\n",
    "    return rates, abs_ind_fitness, abs_gr_fitness\n",
    "\n",
    "#combine individual and group rates to get new rates array\n",
    "#def update_rates(assign_mask, rates, abs_ind_fitness, changed_abs_ind_fitness, event_drawn, group_index, coefficients, epistasis, offspring_ind_genome, parent_ind_genome, rd_row_index, ind_index, population_slice, changed_group, changed_group_index): \n",
    "    \"\"\"\n",
    "    Combines individual and group rates into one array and adds ind/group event, and indexing by event type\n",
    "    Return:\n",
    "    2D array (total number of events, 3): event rates, individual/group 0/1, index of ind or group\n",
    "    \"\"\"\n",
    "    \n",
    "    ind_rates, abs_ind_fitness, changed_abs_ind_fitness = update_ind_rates(assign_mask, ind_rates, abs_ind_fitness, changed_abs_ind_fitness, event_drawn, group_index, coefficients, epistasis, \n",
    "              offspring_ind_genome, parent_ind_genome, rd_row_index, ind_index)\n",
    "    individual = np.zeros_like(ind_rates) #individuals indicated by 0\n",
    "    ind_index = np.arange(ind_rates.shape[0]).reshape(-1, 1) #index of which individual added\n",
    "    ind_rates = np.column_stack((ind_rates, individual, ind_index)) \n",
    "\n",
    "    group_rates = update_gr_rates(event_drawn, population_slice, group_index, changed_group, changed_group_index, coefficients, epistasis)\n",
    "    group = np.ones_like(group_rates) #groups indicated by 1\n",
    "    group_index = np.arange(group_rates.shape[0]).reshape(-1, 1) #index of which group added\n",
    "    group_rates = np.column_stack((group_rates, group, group_index)) \n",
    "\n",
    "    rates = np.vstack((group_rates, ind_rates))\n",
    "\n",
    "    return rates, ind_index, group_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For executing reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ind_reproduction(event_drawn, population, rates):\n",
    "    \"\"\"\n",
    "    -event_drawn: index of selected event (0-total number of events)\n",
    "    -population: current population state\n",
    "    Return\n",
    "    -population_slice: 2D array with updated genomes of group reproduction happened in\n",
    "    \"\"\" \n",
    "    #get parent genome\n",
    "    ind_index = (event_drawn-M) % n #within group \n",
    "    group_index = ((event_drawn-M)//n) #note both ind_index and group_index start at 0\n",
    "    population_slice = population[group_index,:, :] \n",
    "    parent_ind_genome = population_slice[ind_index]\n",
    "    parent_ind_genome = np.array(parent_ind_genome) \n",
    "    rd_row_index = None  \n",
    "    \n",
    "    #get offspring genome and add to slice, remove individual if group is full\n",
    "    offspring_ind_genome = parent_ind_genome \n",
    "    offspring_ind_genome = np.array(offspring_ind_genome)  \n",
    "    match mutation: #no mutation so genome offspring = genome parent\n",
    "        case [\"no\"]:\n",
    "            if np.isnan(population_slice).any(axis=1).any(): #nan rows? group not full- so ind added\n",
    "                nan_row_indices = np.where(np.isnan(population_slice).any(axis=1))[0]\n",
    "                rd_nan_row_index = np.random.choice(nan_row_indices)\n",
    "                population_slice[rd_nan_row_index] = offspring_ind_genome #random nan row replaced by offspring\n",
    "            elif not np.isnan(population_slice).any(): #no nan rows? group full\n",
    "                rd_row_index = np.random.randint(0, population_slice.shape[0])  # randomly select ind for replacement                        \n",
    "                population_slice[rd_row_index] = offspring_ind_genome\n",
    "            else:\n",
    "                raise ValueError(\"group size exceeds max\")\n",
    "        case [\"yes\"]:\n",
    "            mutate = rd.random() < mu\n",
    "            offspring_ind_genome = [1 - x if mutate else x for x in offspring_ind_genome]\n",
    "            if population_slice.shape[0] < n: #group not full- so ind added\n",
    "                population_slice = np.append(population_slice, [offspring_ind_genome], axis=0)\n",
    "            elif population_slice.shape[0] == n:\n",
    "                    rd_row_index = np.random.randint(0, population_slice.shape[0])  #randomly select ind for elimination\n",
    "                    population_slice[rd_row_index] = offspring_ind_genome\n",
    "            else:\n",
    "                raise ValueError(\"group size exceeds max\")\n",
    "    #unchanged_population = np.delete(population, group_index, axis=2)   \n",
    "\n",
    "    return population_slice, offspring_ind_genome, rd_row_index \n",
    "\n",
    "\n",
    "def group_splitting(event_drawn, event_index, population, rates): \n",
    "    \"\"\"\n",
    "    -event_drawn: index of selected event \n",
    "    -population: current population state\n",
    "    Return\n",
    "    -population_slice (updated number of individuals (only in group), with genomes of length N))\n",
    "    \"\"\" \n",
    "    selected_group_index = event_drawn // (N // M)\n",
    "    parent_group = population[selected_group_index, :, :] #from population take correct slice (=group) based on group_index selected event   \n",
    "\n",
    "    #zeros (parent group) or ones (offspring group) randomly assigned to each row of mask array to split\n",
    "    assign_mask = np.random.randint(2, size=parent_group.shape[0])  \n",
    "    parent_group_new = parent_group[assign_mask == 0]\n",
    "    offspring_group = parent_group[assign_mask == 1]\n",
    "\n",
    "    #make sure neither group is empty\n",
    "    if parent_group_new.shape[0] == 0:     #parent group is empty, randomly select one genome from offspring group for transfer\n",
    "        while True:\n",
    "            random_row_index = np.random.randint(0, offspring_group.shape[0])\n",
    "            selected_genome = offspring_group[random_row_index, np.newaxis, :]\n",
    "            if not np.isnan(selected_genome).any(): \n",
    "                break\n",
    "                #repeated until non-empty row is selected for transfer to empty parent group\n",
    "        offspring_group = np.delete(offspring_group, random_row_index, axis=0)\n",
    "        parent_group_new = selected_genome \n",
    "    elif offspring_group.shape[0] == 0:     # offspring group empty, randomly select one genome from parent group for transfer\n",
    "        while True:\n",
    "            random_row_index = np.random.randint(0, parent_group.shape[0])\n",
    "            selected_genome = parent_group[random_row_index, np.newaxis, :]        \n",
    "            if not np.isnan(selected_genome).any(): \n",
    "                break\n",
    "        parent_group_new = np.delete(parent_group, random_row_index, axis=0)\n",
    "        offspring_group = selected_genome\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #add na rows so shape is n,N \n",
    "    rows_to_add_p = n - parent_group_new.shape[0] \n",
    "    rows_to_add_o = n - offspring_group.shape[0]\n",
    "    if rows_to_add_p > 0:\n",
    "        nan_rows_1 = np.full((rows_to_add_p,  N), np.nan)\n",
    "        parent_group_new = np.concatenate((parent_group_new, nan_rows_1), axis=0)\n",
    "    if rows_to_add_o > 0:\n",
    "        nan_rows_2 = np.full((rows_to_add_o, N), np.nan)\n",
    "        offspring_group = np.concatenate((offspring_group, nan_rows_2), axis=0)\n",
    "    \n",
    "    population[selected_group_index] = parent_group_new[np.newaxis, ...]     #replace old parent group with new parent group\n",
    "    population_newadded = np.concatenate((population, offspring_group[np.newaxis, ...]), axis=0)     #add offspring group to population (now 1 more group than maximum (so 4 instead of 3 example))\n",
    "    terminated_group_index = np.random.randint(0, population_newadded.shape[0])     #randomly select a group for termination & remove from population\n",
    "    population = np.delete(population_newadded, terminated_group_index, axis=0) \n",
    "    \n",
    "    #from updated population, correctly extract those groups whose contents changed\n",
    "    if terminated_group_index == population_newadded.shape[0]-1 or terminated_group_index == population_newadded.shape[0] - 2:\n",
    "        #then terminated group is parent or offspring group (because last added) and only 1 changed group remains\n",
    "        if terminated_group_index == population_newadded.shape[0]-1: #(offspring group terminated)\n",
    "            changed_group = population_newadded[-2, :, :] \n",
    "            changed_group_index = population_newadded.shape[0] - 2\n",
    "        else: #terminated_group_index == population.shape[0] - 2 (parent group terminated)\n",
    "            changed_group = population_newadded[-1, :, :]\n",
    "            changed_group_index = population_newadded.shape[0] - 1\n",
    "    else:\n",
    "        #parent and offspring groups both included in the changed groups, not terminated\n",
    "        changed_group = population[-2:, :, :]\n",
    "        changed_group_index = (population.shape[0] - 2, population.shape[0] - 1)  #index of both second last and last slices\n",
    "    \n",
    "    return changed_group, changed_group_index, assign_mask, terminated_group_index\n",
    "\n",
    "def choose_event(rates): \n",
    "    \"\"\"\n",
    "    -rates: array (total number of events): event rates\n",
    "    Return:\n",
    "    integer: index of selected event\n",
    "    \"\"\"\n",
    "    event_index = np.arange(rates.shape[0])\n",
    "    total_rate = np.sum(rates)\n",
    "    probs = rates.flatten() / total_rate #normalized to sum to 1\n",
    "    event_drawn = choice(event_index, 1, p=probs) #randomly selects event base on individual probabilities of each event\n",
    "    event_drawn = event_drawn[0] \n",
    "    return event_drawn, event_index\n",
    "\n",
    "    #event_drawn = np.random.choice(event_index, size=1, p=probs)\n",
    "\n",
    "def execute_reaction(event_drawn, event_index, population):\n",
    "    if event_drawn < M:  \n",
    "        return group_splitting(event_drawn, event_index, population)\n",
    "    elif M < event_drawn < (M + M*n): \n",
    "        return ind_reproduction(event_drawn, population, ind_rates)\n",
    "    else:\n",
    "        raise ValueError(\"invalid event indexed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [0 3]\n",
      " [1 3]\n",
      " [1 0]]\n",
      "[[2 1]\n",
      " [3 2]\n",
      " [3 0]\n",
      " [1 0]]\n",
      "[[ 0.1730922   0.61144105 -0.08712625  0.106592    0.14049139 -0.40340577\n",
      "  -0.21109579  0.58124578]\n",
      " [ 0.42889188 -0.17944919  0.13986244 -0.01828775 -0.29776663  0.99704782\n",
      "  -0.00798591 -1.00675144]\n",
      " [ 0.54747447 -0.11126834 -0.37614033  0.19777541  0.03997309 -0.34475206\n",
      "  -0.15612842  0.48087715]\n",
      " [ 0.99168777 -0.99139825 -0.61270213  1.36223176 -0.52922082  1.51310218\n",
      "   0.85780312 -1.99369239]]\n"
     ]
    }
   ],
   "source": [
    "def initial_rates(init_abs_ind_fitness, init_abs_gr_fitness):\n",
    "    init_rates = []\n",
    "    f_j = np.mean(init_abs_ind_fitness, axis=1) \n",
    "    w_j = init_abs_ind_fitness / f_j[:, None]    \n",
    "    ind_rates = w_j.flatten()\n",
    "    ind_rates = w_j.reshape(-1, 1)  \n",
    "    F = np.mean(init_abs_gr_fitness)\n",
    "    W = init_abs_gr_fitness / F\n",
    "    gr_rates = alpha * W\n",
    "    init_rates = np.vstack((gr_rates, ind_rates))\n",
    "    return init_rates\n",
    "\n",
    "t=0\n",
    "# CONSTRUCT FITNESS LANDSCAPES \n",
    "fm_i = create_fitness_matrix_i()\n",
    "fm_g = create_fitness_matrix_g()\n",
    "# Construct epistasis matrices\n",
    "em_i = create_epistasis_matrix_i()\n",
    "em_g = create_epistasis_matrix_g()\n",
    "\n",
    "print(em_i)\n",
    "print(em_g)\n",
    "#coefficients\n",
    "coef_i = np.array(calc_a(fm_i))\n",
    "coef_g = np.array(calc_a(fm_g))\n",
    "\n",
    "print(coef_g)\n",
    "#initial population\n",
    "population = np.zeros(shape=(M,n,N))\n",
    "gr_genomes = np.mean(population, axis=1)\n",
    "#print(population)\n",
    "abs_ind_fitness = calculate_fitness(coef_i, em_i, population)\n",
    "abs_ind_fitness = abs_ind_fitness.reshape(-1,1)\n",
    "abs_gr_fitness = calculate_fitness(coef_g, em_g, gr_genomes) \n",
    "abs_gr_fitness = abs_gr_fitness.reshape(-1,1)\n",
    "rates = initial_rates(abs_ind_fitness, abs_gr_fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for running simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "propensity [15.3]\n",
      "time [0.13035792] tau [0.13035792]\n",
      "propensity [15.3]\n",
      "time [0.14655097] tau [0.01619305]\n",
      "propensity [15.3]\n",
      "time [0.20102475] tau [0.05447378]\n",
      "propensity [15.3]\n",
      "time [0.20291201] tau [0.00188726]\n",
      "propensity [15.3]\n",
      "time [0.20750417] tau [0.00459217]\n",
      "propensity [15.3]\n",
      "time [0.31817944] tau [0.11067527]\n",
      "propensity [15.3]\n",
      "time [0.35159349] tau [0.03341405]\n",
      "propensity [15.3]\n",
      "time [0.41373278] tau [0.06213929]\n",
      "propensity [15.3]\n",
      "time [0.44311819] tau [0.02938541]\n",
      "propensity [15.3]\n",
      "time [0.47988788] tau [0.03676968]\n",
      "propensity [15.3]\n",
      "time [0.58528407] tau [0.10539619]\n",
      "propensity [15.3]\n",
      "time [0.60984139] tau [0.02455733]\n",
      "propensity [15.3]\n",
      "time [0.68391038] tau [0.07406899]\n",
      "propensity [15.3]\n",
      "time [0.70862714] tau [0.02471676]\n",
      "propensity [15.3]\n",
      "time [0.73010163] tau [0.02147448]\n",
      "propensity [15.3]\n",
      "time [0.7506561] tau [0.02055448]\n",
      "propensity [15.3]\n",
      "time [0.78742792] tau [0.03677182]\n",
      "propensity [15.3]\n",
      "time [0.78914299] tau [0.00171507]\n",
      "propensity [15.3]\n",
      "time [0.92583109] tau [0.1366881]\n",
      "propensity [15.3]\n",
      "time [1.12494511] tau [0.19911402]\n",
      "propensity [15.3]\n",
      "time [1.25556462] tau [0.13061951]\n",
      "propensity [15.3]\n",
      "time [1.26514831] tau [0.00958369]\n",
      "propensity [15.3]\n",
      "time [1.41342644] tau [0.14827813]\n",
      "propensity [15.3]\n",
      "time [1.4313791] tau [0.01795266]\n",
      "propensity [15.3]\n",
      "time [1.44352125] tau [0.01214215]\n",
      "propensity [15.3]\n",
      "time [1.45787697] tau [0.01435572]\n",
      "propensity [15.3]\n",
      "time [1.55561409] tau [0.09773712]\n",
      "propensity [15.3]\n",
      "time [1.63998717] tau [0.08437308]\n",
      "propensity [15.3]\n",
      "time [1.68506769] tau [0.04508052]\n",
      "propensity [15.3]\n",
      "time [1.80612318] tau [0.12105548]\n",
      "propensity [15.3]\n",
      "time [1.91596885] tau [0.10984567]\n",
      "propensity [15.3]\n",
      "time [1.9385471] tau [0.02257824]\n",
      "propensity [15.3]\n",
      "time [1.96977446] tau [0.03122737]\n",
      "propensity [15.3]\n",
      "time [1.97400362] tau [0.00422916]\n",
      "propensity [15.3]\n",
      "time [2.13015675] tau [0.15615312]\n",
      "propensity [15.3]\n",
      "time [2.20507178] tau [0.07491504]\n",
      "propensity [15.3]\n",
      "time [2.25841331] tau [0.05334152]\n",
      "propensity [15.3]\n",
      "time [2.29064205] tau [0.03222875]\n",
      "propensity [15.3]\n",
      "time [2.30420836] tau [0.01356631]\n",
      "propensity [15.3]\n",
      "time [2.47708175] tau [0.17287339]\n",
      "propensity [15.3]\n",
      "time [2.71803306] tau [0.24095132]\n",
      "propensity [15.3]\n",
      "time [2.79307717] tau [0.07504411]\n",
      "propensity [15.3]\n",
      "time [2.94358394] tau [0.15050677]\n",
      "propensity [15.3]\n",
      "time [3.02107677] tau [0.07749283]\n",
      "propensity [15.3]\n",
      "time [3.07777299] tau [0.05669622]\n",
      "propensity [15.3]\n",
      "time [3.11293605] tau [0.03516306]\n",
      "propensity [15.3]\n",
      "time [3.1976905] tau [0.08475445]\n",
      "propensity [15.3]\n",
      "time [3.34789778] tau [0.15020728]\n",
      "propensity [15.3]\n",
      "time [3.4438271] tau [0.09592932]\n",
      "propensity [15.3]\n",
      "time [3.48767845] tau [0.04385134]\n",
      "propensity [15.3]\n",
      "time [3.61330754] tau [0.1256291]\n",
      "propensity [10.3]\n",
      "time [3.73312001] tau [0.11981246]\n",
      "propensity [10.3]\n",
      "time [3.73653506] tau [0.00341506]\n",
      "propensity [10.3]\n",
      "time [3.77894299] tau [0.04240792]\n",
      "propensity [10.3]\n",
      "time [3.78020564] tau [0.00126265]\n",
      "propensity [10.3]\n",
      "time [3.89292658] tau [0.11272094]\n",
      "propensity [10.3]\n",
      "time [3.9846191] tau [0.09169252]\n",
      "propensity [10.3]\n",
      "time [4.13580658] tau [0.15118748]\n",
      "propensity [10.3]\n",
      "time [4.16687792] tau [0.03107134]\n",
      "propensity [10.3]\n",
      "time [4.22795819] tau [0.06108027]\n",
      "propensity [10.3]\n",
      "time [4.35204402] tau [0.12408583]\n",
      "propensity [10.3]\n",
      "time [4.55643203] tau [0.20438801]\n",
      "propensity [10.3]\n",
      "time [4.60418475] tau [0.04775272]\n",
      "propensity [10.3]\n",
      "time [4.60727784] tau [0.00309309]\n",
      "propensity [10.3]\n",
      "time [4.64607441] tau [0.03879657]\n",
      "propensity [10.3]\n",
      "time [4.9446979] tau [0.29862349]\n",
      "propensity [10.3]\n",
      "time [4.96529493] tau [0.02059703]\n",
      "propensity [10.3]\n",
      "time [5.13985382] tau [0.17455889]\n",
      "propensity [10.3]\n",
      "time [5.30990622] tau [0.1700524]\n",
      "propensity [10.3]\n",
      "time [5.55960637] tau [0.24970015]\n",
      "propensity [10.3]\n",
      "time [5.78498051] tau [0.22537414]\n",
      "propensity [10.3]\n",
      "time [5.83113879] tau [0.04615827]\n",
      "propensity [10.3]\n",
      "time [5.90077282] tau [0.06963404]\n",
      "propensity [10.3]\n",
      "time [6.0010043] tau [0.10023148]\n",
      "propensity [10.3]\n",
      "time [6.00147155] tau [0.00046725]\n",
      "propensity [10.3]\n",
      "time [6.08284911] tau [0.08137756]\n",
      "propensity [10.3]\n",
      "time [6.13874913] tau [0.05590002]\n",
      "propensity [10.3]\n",
      "time [6.16941832] tau [0.0306692]\n",
      "propensity [10.3]\n",
      "time [6.27396603] tau [0.10454771]\n",
      "propensity [10.3]\n",
      "time [6.42923975] tau [0.15527372]\n",
      "propensity [10.3]\n",
      "time [6.59094903] tau [0.16170927]\n",
      "propensity [10.3]\n",
      "time [6.81684245] tau [0.22589343]\n",
      "propensity [10.3]\n",
      "time [6.93372319] tau [0.11688073]\n",
      "propensity [10.3]\n",
      "time [7.11027782] tau [0.17655464]\n",
      "propensity [10.3]\n",
      "time [7.17339079] tau [0.06311296]\n",
      "propensity [10.3]\n",
      "time [7.49606702] tau [0.32267623]\n",
      "propensity [10.3]\n",
      "time [7.51170206] tau [0.01563504]\n",
      "propensity [10.3]\n",
      "time [7.64318845] tau [0.1314864]\n",
      "propensity [10.3]\n",
      "time [7.7089224] tau [0.06573395]\n",
      "propensity [10.3]\n",
      "time [7.72135945] tau [0.01243705]\n",
      "propensity [10.3]\n",
      "time [7.92872979] tau [0.20737034]\n",
      "propensity [10.3]\n",
      "time [7.99209663] tau [0.06336684]\n",
      "propensity [10.3]\n",
      "time [8.00032898] tau [0.00823235]\n",
      "propensity [10.3]\n",
      "time [8.04496312] tau [0.04463414]\n",
      "propensity [10.3]\n",
      "time [8.04654345] tau [0.00158033]\n",
      "propensity [10.3]\n",
      "time [8.12206875] tau [0.0755253]\n",
      "propensity [10.3]\n",
      "time [8.15643332] tau [0.03436456]\n",
      "propensity [10.3]\n",
      "time [8.1884478] tau [0.03201448]\n",
      "propensity [10.3]\n",
      "time [8.20068735] tau [0.01223955]\n",
      "propensity [10.3]\n",
      "time [8.32010405] tau [0.1194167]\n",
      "propensity [10.3]\n",
      "time [8.32741644] tau [0.00731239]\n",
      "propensity [10.3]\n",
      "time [8.36459032] tau [0.03717388]\n",
      "propensity [10.3]\n",
      "time [8.38251631] tau [0.01792599]\n",
      "propensity [10.3]\n",
      "time [8.49934765] tau [0.11683134]\n",
      "propensity [10.3]\n",
      "time [8.59010239] tau [0.09075473]\n",
      "propensity [10.3]\n",
      "time [8.69459239] tau [0.10449001]\n",
      "propensity [10.3]\n",
      "time [8.7347716] tau [0.04017921]\n",
      "propensity [10.3]\n",
      "time [8.76601276] tau [0.03124117]\n",
      "propensity [10.3]\n",
      "time [8.88892927] tau [0.1229165]\n",
      "propensity [10.3]\n",
      "time [8.88961945] tau [0.00069018]\n",
      "propensity [10.3]\n",
      "time [8.88981676] tau [0.00019731]\n",
      "propensity [10.3]\n",
      "time [8.91227603] tau [0.02245927]\n",
      "propensity [10.3]\n",
      "time [8.96631365] tau [0.05403762]\n",
      "propensity [10.3]\n",
      "time [9.00621315] tau [0.0398995]\n",
      "propensity [10.3]\n",
      "time [9.48091056] tau [0.47469741]\n",
      "propensity [10.3]\n",
      "time [9.4939939] tau [0.01308334]\n",
      "propensity [10.3]\n",
      "time [9.5149152] tau [0.02092131]\n",
      "propensity [10.3]\n",
      "time [9.53506527] tau [0.02015006]\n",
      "propensity [10.3]\n",
      "time [9.66220985] tau [0.12714459]\n",
      "propensity [10.3]\n",
      "time [9.66708518] tau [0.00487533]\n",
      "propensity [10.3]\n",
      "time [9.89748389] tau [0.23039871]\n",
      "propensity [10.3]\n",
      "time [10.17572045] tau [0.27823656]\n",
      "End time reached: 10\n",
      "End time: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9324\\4199632977.py:151: RuntimeWarning: Mean of empty slice\n",
      "  changed_f_j = np.nanmean(abs_ind_fitness, axis=1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9324\\4199632977.py:134: RuntimeWarning: Mean of empty slice\n",
      "  changed_f_j = np.nanmean(abs_ind_fitness, axis=1) #average group fitness  = average of ind fitnesses check if taking changed or all\n"
     ]
    }
   ],
   "source": [
    "while t < t_end :\n",
    "    # Choose the next event based on the current rates\n",
    "    event_drawn, event_index = choose_event(rates)\n",
    "    if event_drawn < M:  \n",
    "        changed_group, changed_group_index, assign_mask, terminated_group_index = group_splitting(event_drawn, event_index, population, rates)\n",
    "        rates, abs_ind_fitness, abs_gr_fitness = update_rates_grsplit(abs_ind_fitness, abs_gr_fitness, event_drawn, changed_group, changed_group_index, assign_mask, terminated_group_index, coef_g, em_g)\n",
    "    elif M-1 < event_drawn < (M + M*n): \n",
    "        population_slice, offspring_ind_genome, rd_row_index = ind_reproduction(event_drawn, population, rates)\n",
    "        rates, abs_ind_fitness, abs_gr_fitness = update_rates_indrep(event_drawn, population_slice, abs_ind_fitness, abs_gr_fitness, coef_i, em_i, offspring_ind_genome, rd_row_index, coef_g, em_g)\n",
    "    else:\n",
    "        raise ValueError(\"invalid event indexed\")\n",
    "    propensity = sum(rates)\n",
    "    print(\"propensity\", propensity)\n",
    "    tau = np.random.exponential(scale=1 / propensity)\n",
    "    # Update time\n",
    "    t = t + tau\n",
    "    print(\"time\", t, \"tau\", tau)\n",
    "    if t >= t_end:\n",
    "        t = t_end\n",
    "        print(\"End time reached:\", t)\n",
    "        print(\"End time:\", t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
